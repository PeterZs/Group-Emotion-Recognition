{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Face and Label Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Using Google Vision API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Google Vision Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement Face Detection function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_google(face_file, max_results=4):\n",
    "    \"\"\"Uses the Vision API to detect faces in the given file.\n",
    "\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "\n",
    "    Returns:\n",
    "        An array of Face objects with information about the picture.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    content = face_file.read()\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    return client.face_detection(image=image).face_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement Label Detection function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_labels_google(path):\n",
    "    \"\"\"Detects labels in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    print('Labels:')\n",
    "\n",
    "    for label in labels:\n",
    "        print(label.description)\n",
    "    \n",
    "    labels_list = [label.description for label in labels]\n",
    "    \n",
    "    return labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Using OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(face_file):\n",
    "    # load our serialized model from disk\n",
    "    print('[INFO] loading model...')\n",
    "    net = cv2.dnn.readNetFromCaffe('deploy.prototxt.txt',\n",
    "                                   'res10_300x300_ssd_iter_140000.caffemodel'\n",
    "                                   )\n",
    "\n",
    "    # load the input image and construct an input blob for the image\n",
    "    # by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "    image = cv2.imread(face_file)\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300,\n",
    "                                 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    # pass the blob through the network and obtain the detections and\n",
    "    # predictions\n",
    "    print('[INFO] computing object detections...')\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_faces(image_file, cropped_images_path, faces):\n",
    "    count = 1\n",
    "    image = Image.open(image_file)\n",
    "    \n",
    "    if not faces:\n",
    "        print(\"No face detected in the image.\")\n",
    "        return\n",
    "    \n",
    "#     print(len(faces))\n",
    "    \n",
    "    for face in faces:\n",
    "        coordinates = [(vertex.x, vertex.y)\n",
    "            for vertex in face.bounding_poly.vertices]\n",
    "        \n",
    "        x_coordinates, y_coordinates = [], []\n",
    "        for vertex in face.bounding_poly.vertices:\n",
    "            x_coordinates.append(vertex.x)\n",
    "            y_coordinates.append(vertex.y)\n",
    "        \n",
    "        x0, x1, y0, y1 = x_coordinates[0], x_coordinates[2], y_coordinates[0], y_coordinates[2]\n",
    "        \n",
    "        box = (x0, y0, x1, y1)\n",
    "        cropped_image = image.crop(box)\n",
    "                                                              \n",
    "        image_name = (image_file.split(\"/\")[-1])[:-4]\n",
    "        cropped_image.save(cropped_images_path + image_name + \"_face_\" + str(count) + \".jpg\")\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_faces(cropped_images_path, scaled_images_path, size):\n",
    "    count = 1\n",
    "    for file in glob.glob(cropped_images_path+\"*.jpg\"):\n",
    "        image = cv2.imread(file)\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        height_ratio, width_ratio = float(size/height), float(size/width)\n",
    "\n",
    "        resized = cv2.resize(image, None, fx=width_ratio, fy=height_ratio, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "#         print(file)\n",
    "        image_name = (file.split(\"/\")[-1])\n",
    "        cv2.imwrite(scaled_images_path + image_name, resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [[\"emotiw/train/Positive/\", \"Faces/train/Positive/\", \"Scaled/train/Positive/\"], [\"emotiw/val/Positive/\", \"Faces/val/Positive/\", \"Scaled/val/Positive/\"], [\"emotiw/val/Neutral/\", \"Faces/val/Neutral/\", \"Scaled/val/Neutral/\"], [\"emotiw/val/Negative/\", \"Faces/val/Negative/\", \"Scaled/val/Negative/\"], [\"emotiw/train/Neutral/\", \"Faces/train/Neutral/\", \"Scaled/train/Neutral/\"], [\"emotiw/train/Negative/\", \"Faces/train/Negative/\", \"Scaled/train/Negative/\"]]\n",
    "\n",
    "for image_category in images:\n",
    "    for image_file in sorted(glob.glob(image_category[0]+\"*.jpg\")):\n",
    "        print(image_file)\n",
    "        with open(image_file, 'rb') as image:\n",
    "            faces = detect_face_google(image)\n",
    "\n",
    "            # Reset the file pointer, so we can read the file again\n",
    "            image.seek(0)\n",
    "            crop_faces(image_file, image_category[1], faces)\n",
    "        break\n",
    "    break\n",
    "\n",
    "    resize_faces(image_category[1], image_category[2], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
